<!doctype html><html lang=en-us dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.148.1"><meta name=generator content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862"><meta name=description content="üèÜ Announcement: Winners of the 2025 TLAi+ Challenge The TLA+ Foundation, in collaboration with NVIDIA, is pleased to announce the winners of the first GenAI-accelerated TLA+ Challenge‚Äîan open call for submissions showcasing creative and technically impressive work at the intersection of TLA+, formal methods, and AI-assisted development.
ü•á First Place ‚Äî Specula (Code ‚Üí Spec) Specula, developed by Qian Cheng, Dr. Tianyin Xu, and Dr. Yu Huang, is an open-source framework that automatically derives TLA+ specifications from source code and checks them against the implementation. It combines an LLM-based generator with a Control Flow Analyzer to ensure syntactic and structural correctness, then uses trace validation to semantically align the spec and the implementation. Demonstrated on etcd‚Äôs Raft (Go) and Asterinas‚Äôs SpinLock (Rust), Specula offers a reproducible path toward scaling automated specification to broader codebases and abstracting algorithmic intent. Specula was presented at the TLA+ Community Meeting on November 12."><meta name=author content="TLA+ Foundation"><meta name=twitter:card content="summary"><meta name=twitter:title content="GenAI-accelerated TLA+ challenge :: TLA+ Foundation"><meta name=twitter:description content="üèÜ Announcement: Winners of the 2025 TLAi+ Challenge The TLA+ Foundation, in collaboration with NVIDIA, is pleased to announce the winners of the first GenAI-accelerated TLA+ Challenge‚Äîan open call for submissions showcasing creative and technically impressive work at the intersection of TLA+, formal methods, and AI-assisted development.
ü•á First Place ‚Äî Specula (Code ‚Üí Spec) Specula, developed by Qian Cheng, Dr. Tianyin Xu, and Dr. Yu Huang, is an open-source framework that automatically derives TLA+ specifications from source code and checks them against the implementation. It combines an LLM-based generator with a Control Flow Analyzer to ensure syntactic and structural correctness, then uses trace validation to semantically align the spec and the implementation. Demonstrated on etcd‚Äôs Raft (Go) and Asterinas‚Äôs SpinLock (Rust), Specula offers a reproducible path toward scaling automated specification to broader codebases and abstracting algorithmic intent. Specula was presented at the TLA+ Community Meeting on November 12."><meta property="og:url" content="https://foundation.tlapl.us/challenge/"><meta property="og:site_name" content="TLA+ Foundation"><meta property="og:title" content="GenAI-accelerated TLA+ challenge"><meta property="og:description" content=" üèÜ Announcement: Winners of the 2025 TLAi+ Challenge The TLA+ Foundation, in collaboration with NVIDIA, is pleased to announce the winners of the first GenAI-accelerated TLA+ Challenge‚Äîan open call for submissions showcasing creative and technically impressive work at the intersection of TLA+, formal methods, and AI-assisted development.
ü•á First Place ‚Äî Specula (Code ‚Üí Spec) Specula, developed by Qian Cheng, Dr. Tianyin Xu, and Dr. Yu Huang, is an open-source framework that automatically derives TLA+ specifications from source code and checks them against the implementation. It combines an LLM-based generator with a Control Flow Analyzer to ensure syntactic and structural correctness, then uses trace validation to semantically align the spec and the implementation. Demonstrated on etcd‚Äôs Raft (Go) and Asterinas‚Äôs SpinLock (Rust), Specula offers a reproducible path toward scaling automated specification to broader codebases and abstracting algorithmic intent. Specula was presented at the TLA+ Community Meeting on November 12.
"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta itemprop=name content="GenAI-accelerated TLA+ challenge :: TLA+ Foundation"><meta itemprop=description content="üèÜ Announcement: Winners of the 2025 TLAi+ Challenge The TLA+ Foundation, in collaboration with NVIDIA, is pleased to announce the winners of the first GenAI-accelerated TLA+ Challenge‚Äîan open call for submissions showcasing creative and technically impressive work at the intersection of TLA+, formal methods, and AI-assisted development.
ü•á First Place ‚Äî Specula (Code ‚Üí Spec) Specula, developed by Qian Cheng, Dr. Tianyin Xu, and Dr. Yu Huang, is an open-source framework that automatically derives TLA+ specifications from source code and checks them against the implementation. It combines an LLM-based generator with a Control Flow Analyzer to ensure syntactic and structural correctness, then uses trace validation to semantically align the spec and the implementation. Demonstrated on etcd‚Äôs Raft (Go) and Asterinas‚Äôs SpinLock (Rust), Specula offers a reproducible path toward scaling automated specification to broader codebases and abstracting algorithmic intent. Specula was presented at the TLA+ Community Meeting on November 12."><meta itemprop=datePublished content="2025-05-03T00:00:00+00:00"><meta itemprop=dateModified content="2025-05-03T00:00:00+00:00"><meta itemprop=wordCount content="749"><title>GenAI-accelerated TLA+ challenge :: TLA+ Foundation</title><link href=/challenge/index.xml rel=alternate type=application/rss+xml title="GenAI-accelerated TLA+ challenge :: TLA+ Foundation"><link href=/fonts/fontawesome/css/fontawesome-all.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/fonts/fontawesome/css/fontawesome-all.min.css rel=stylesheet></noscript><link href=/css/perfect-scrollbar/perfect-scrollbar.min.css rel=stylesheet><link href=/css/theme.min.css rel=stylesheet><link href=/css/format-html.min.css rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/challenge/index.html",window.relearn.relBasePath="..",window.relearn.relBaseUri="..",window.relearn.absBaseUri="https://foundation.tlapl.us",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!1,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.relearn.themevariants=["tlaplus"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script></head><body class="mobile-support html" data-url=/challenge/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>TLA+ Foundation</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>GenAI-accelerated TLA+ challenge</span><meta itemprop=position content="2"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable challenge" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=genai-accelerated-tla-challenge>GenAI-accelerated TLA+ challenge</h1><figure><img src=/challenge/banner.png alt="TLAi+ logo"></figure><h6 id=-announcement-winners-of-the-2025-tlai-challenge>üèÜ <strong>Announcement: Winners of the 2025 TLAi+ Challenge</strong></h6><span style=font-size:20px><p>The TLA+ Foundation, in collaboration with <a href=https://www.nvidia.com/en-us/ rel=external target=_blank>NVIDIA</a>, is pleased to announce the winners of the first GenAI-accelerated TLA+ Challenge‚Äîan open call for submissions showcasing creative and technically impressive work at the intersection of TLA+, formal methods, and AI-assisted development.</p></span><h6 id=-first-place--specula><strong>ü•á First Place ‚Äî Specula <em>(Code ‚Üí Spec)</em></strong></h6><span style=font-size:1.3em><p><a href=https://github.com/specula-org/Specula rel=external target=_blank>Specula</a>, developed by <a href=https://github.com/Qian-Cheng-nju rel=external target=_blank>Qian Cheng</a>, <a href=https://siebelschool.illinois.edu/about/people/faculty/tyxu rel=external target=_blank>Dr. Tianyin Xu</a>, and <a href=https://cs.nju.edu.cn/yuhuang/ rel=external target=_blank>Dr. Yu Huang</a>, is an open-source framework that automatically derives TLA+ specifications from source code and checks them against the implementation. It combines an LLM-based generator with a Control Flow Analyzer to ensure syntactic and structural correctness, then uses trace validation to semantically align the spec and the implementation. Demonstrated on etcd‚Äôs Raft (Go) and Asterinas‚Äôs SpinLock (Rust), Specula offers a reproducible path toward scaling automated specification to broader codebases and abstracting algorithmic intent. Specula <a href="https://www.youtube.com/watch?v=BoIjXJXN3GU&t=771s" rel=external target=_blank>was presented at the TLA+ Community Meeting on November 12</a>.</p><figure><img src=/challenge/SpeculaWinners.jpeg alt="A virtual meeting screenshot showing the three winners of the TLAI+ GenAI Challenge along with their prize, an NVIDIA 5090 graphics card displayed in the bottom left corner." width=400 height=224></figure><p><strong>Award</strong>: <a href=https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/rtx-5090/ rel=external target=_blank>Nvidia GeForce RTX 5090</a> (sponsored by NVIDIA)</p></span><h6 id=-second-place--andrew-helwer><strong>ü•à Second Place ‚Äî Andrew Helwer <em>(LLM Token Restriction)</em></strong></h6><span style=font-size:1.3em><p><a href=https://ahelwer.ca rel=external target=_blank>Andrew</a> tested whether <a href=https://codeberg.org/tlaplus/tla-constrain-llm rel=external target=_blank>local LLMs can be constrained to produce valid TLA+</a> by restricting token generation. Using LlamaCpp‚Äôs GBNF syntax (context-free) and the Guidance framework (context-sensitive), he showed that grammar-based constraints can reliably enforce syntax and, in some cases, symbol definition. Adding TLA+ documentation to prompts improved results, and the language‚Äôs explicit symbol declarations make it well-suited to such constraints. This approach could complement or even surpass fine-tuning for niche languages.</p><p><strong>Award</strong>: One-year single seat, individual subscription to <a href=https://github.com/github-copilot/pro-plus rel=external target=_blank>Github Copilot Pro+</a> (sponsored by the TLA+ Foundation)</p></span><h6 id=-third-place--gregory-terzian><strong>ü•â Third Place ‚Äî Gregory Terzian <em>(Spec ‚Üí Code)</em></strong></h6><span style=font-size:1.3em><p><a href=https://github.com/gterzian rel=external target=_blank>Gregory</a> explored using <a href=https://github.com/gterzian/_refinement rel=external target=_blank>TLA+ as a blueprint for generating idiomatic, multithreaded Rust code</a>. By applying TLA+‚Äôs refinement process in stages, the LLM is guided toward correct and efficient implementations, avoiding the ambiguity of natural language instructions. If this approach were combined with new TLA+ MCP server integrations, it could pave the way to fully verified, spec-driven code generation.</p><p><strong>Award</strong>: One-year single seat, individual subscription to <a href=https://github.com/github-copilot/pro rel=external target=_blank>Github Copilot Pro</a> (sponsored by the TLA+ Foundation)</p></span><h6 id=-acknowledgements>üôè <strong>Acknowledgements</strong></h6><span style=font-size:1.3em><p>We warmly thank all participants for their submissions. The challenge was made possible thanks to NVIDIA and the TLA+ Foundation, whose generous sponsorship funded the prizes. We also invite other companies to consider donating prizes for future challenges to help grow the TLA+ ecosystem. For those with larger, longer-term projects in mind, remember that the <a href=https://foundation.tlapl.us/grants/index.html rel=external target=_blank>TLA+ Grants Program</a> is open for proposals year-round.</p></span><hr><p style=text-align:center>The rest of this page is retained in its original form, preserved for posterity.</p><h4 id=example-project-areas><strong>Example Project Areas</strong></h4><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/JX_kTGHoYT8?autoplay=1&amp;controls=0&amp;end=0&amp;loop=1&amp;mute=1&amp;playlist=JX_kTGHoYT8&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>Participants may submit work including, but not limited to:</p><ul><li>Intelligent refactoring of TLA+ specifications (e.g., managing <code>UNCHANGED</code> correctly when adding variables)</li><li>LLM-enhanced linters, formatters, or other development tools</li><li>LLM-driven tools for automated grading in education</li><li>Visualizations of specifications or execution traces</li><li>Generation of type annotations for tools like Apalache</li><li>Synthesis of inductive invariant candidates, validated via <a href=https://github.com/tlaplus/tlaplus rel=external target=_blank>TLC</a> or <a href=https://github.com/apalache-mc/apalache/ rel=external target=_blank>Apalache</a></li><li>Synthesis of <a href=https://github.com/tlaplus/tlapm rel=external target=_blank>TLAPS</a> proofs</li><li>Synthesis of entire specifications from source code and design documents</li></ul><h4 id=evaluation><strong>Evaluation</strong></h4><p>Submissions will be judged by the <strong>TLA+ Specification Language Committee (SLC)</strong></p><p>The Jury will evaluate submissions based on their functionality, relevance to the TLA+ ecosystem, and the thoughtful use of AI. Submissions must be reproducible by the Jury. Passive formats, such as videos alone, are not sufficient. However, the Jury does not require a fully polished product‚Äîa prototype is sufficient. All submissions must be released under the <a href=https://opensource.org/license/mit rel=external target=_blank>MIT license</a>, and any underlying AI models must be publicly available.</p><p>The use of GenAI/LLMs is explicitly encouraged, provided that any AI-generated content‚Äîsuch as specs, invariants, visualizations, ‚Ä¶ ‚Äîis checked using some form of verification such as the TLA+ tools.</p><details open class="box cstyle notices accent"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-bullhorn"></i>
<span class=a11y-only>Details</span></summary><div class=box-content><p>Catch the <a href=https://youtu.be/oFfTuHuTnVw rel=external target=_blank>live announcement</a> at the <a href=https://conf.tlapl.us/2025-etaps rel=external target=_blank>TLA+ Community Event 2025</a>!</p></div></details><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/oFfTuHuTnVw?autoplay=0&amp;controls=1&amp;end=0&amp;loop=1&amp;mute=0&amp;playlist=oFfTuHuTnVw&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><h4 id=participation-criteria><strong>Participation Criteria</strong></h4><p>Eligible participants must meet the following:</p><ul><li>Prior engagement with the TLA+ community (e.g., contribution to <a href=https://groups.google.com/g/tlaplus rel=external target=_blank>mailing lists</a>, <a href=https://www.reddit.com/r/tlaplus/ rel=external target=_blank>forums</a>, <a href=https://github.com/tlaplus/ rel=external target=_blank>open-source repositories</a>, <a href=https://conf.tlapl.us/ rel=external target=_blank>conference presentations</a>, or <a href="https://scholar.google.com/scholar?q=TLA%2B" rel=external target=_blank>academic publications</a>)</li><li>Must not be a member of the TLA+ Foundation Board or Specification Language Committee</li><li>Must not be subject to any legal, contractual, export control, or jurisdictional restrictions that would preclude participation</li></ul><h4 id=submission-timeline--announcement><strong>Submission Timeline & Announcement</strong></h4><p>Submissions will open alongside this announcement. The deadline to submit entries for the challenge is <em>July 3, 2025</em>. Submissions must be sent to <a href=mailto:genai@tlapl.us rel=external target=_blank>genai@tlapl.us</a>. The jury will select the winner one month after the submission period closes. We welcome innovative, technically robust, and practically valuable contributions that explore and expand the potential of GenAI within the context of TLA+.</p><p>For longer-term or foundational engineering and research efforts related to TLA+, we encourage you to explore the <a href=/grants/2024-grant-program/index.html>TLA+ grant program</a>.</p><footer class=footline><hr><p>Copyright ¬© The Linux Foundation ¬Æ. All rights reserved.
The Linux Foundation has registered trademarks and uses trademarks.
For a list of trademarks of The Linux Foundation, please see our
<a href=https://www.linuxfoundation.org/legal/trademarks>Trademark Usage</a> page.</p></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><img src=https://foundation.tlapl.us/logos/tla.jpg alt="The TLA+ logo"></div></div><div id=R-homelinks class="default-animation homelinks"><div class="R-sidebarmenu R-shortcutmenu-homelinks"><ul class="space collapsible-menu"><li data-nav-id=/index.html><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul></div><div class="R-sidebarmenu R-shortcutmenu-headercontrols"><ul></ul></div></div><div id=R-content-wrapper class=highlightable><div class="R-sidebarmenu R-shortcutmenu-main"><ul class="enlarge morespace collapsible-menu"><li data-nav-id=/blog/index.html><a class=padding href=/blog/index.html><i class='fa-fw fas fa-blog'></i> TLA+ Blog</a><ul id=R-subsections-c061e150208a7ab43c1b0b723b79816b class=collapsible-menu></ul></li><li class=alwaysopen data-nav-id=/grants/index.html><a class=padding href=/grants/index.html><i class='fa-fw fas fa-building-columns'></i> TLA+ Foundation Grants</a><ul id=R-subsections-bf83bdd8d2bc462bc2b67f31343a1032 class=collapsible-menu></ul></li><li data-nav-id=/industry/index.html><a class=padding href=/industry/index.html><i class='fa-solid fa-users'></i> Industrial Use of TLA‚Å∫</a></li><li class=active data-nav-id=/challenge/index.html><a class=padding href=/challenge/index.html><i class='fa-solid fa-trophy'></i> GenAI-accelerated TLA+ challenge</a></li></ul></div><div class="R-sidebarmenu R-shortcutmenu-shortcuts"><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-id=https://github.com/tlaplus/><a class=padding href=https://github.com/tlaplus/ rel=external target=_blank><i class="fa-fw fab fa-github"></i> GitHub</a></li><li data-nav-id=https://groups.google.com/g/tlaplus/><a class=padding href=https://groups.google.com/g/tlaplus/ rel=external target=_blank><i class="fa-fw fas fa-at"></i> Mailing List</a></li><li data-nav-id=https://discuss.tlapl.us/><a class=padding href=https://discuss.tlapl.us/ rel=external target=_blank><i class="fa-fw fas fa-inbox"></i> Mailing List Archive</a></li><li data-nav-id=https://conf.tlapl.us/home/><a class=padding href=https://conf.tlapl.us/home/ rel=external target=_blank><i class="fa-fw fas fa-calendar-day"></i> Conferences and Events</a></li></ul></div><div id=R-footer-margin></div><div class="R-sidebarmenu R-shortcutmenu-footercontrols"><ul></ul></div><div id=R-footer></div></div></aside><script src=/js/clipboard/clipboard.min.js defer></script><script src=/js/perfect-scrollbar/perfect-scrollbar.min.js defer></script><script src=/js/theme.min.js defer></script></body></html>